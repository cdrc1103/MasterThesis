{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "BERT_TPU",
   "provenance": [],
   "collapsed_sections": [],
   "authorship_tag": "ABX9TyN63wQmxnXGdlZtEp52nk0O"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "db5eb39114ed491a96153a078f3ce85a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6c1d41aabda24e88985ca802700cb54c",
       "IPY_MODEL_5b4e4549b5c64d9088152c2ae75b5c45"
      ],
      "layout": "IPY_MODEL_92bbb8bb084848acb8dc97d869644f17"
     }
    },
    "6c1d41aabda24e88985ca802700cb54c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_21268d1d8dce4e1b9c558afe247d98e4",
      "max": 2871,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_01ac43b610864af5ad6c7f4323ad649d",
      "value": 2871
     }
    },
    "5b4e4549b5c64d9088152c2ae75b5c45": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_50cd93245a284ab9b3c5cf69e4cc2e21",
      "placeholder": "​",
      "style": "IPY_MODEL_c852a054befd4069b74de1fd94d13ca9",
      "value": " 2871/2871 [00:41&lt;00:00, 68.91ba/s]"
     }
    },
    "92bbb8bb084848acb8dc97d869644f17": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21268d1d8dce4e1b9c558afe247d98e4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "01ac43b610864af5ad6c7f4323ad649d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "50cd93245a284ab9b3c5cf69e4cc2e21": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c852a054befd4069b74de1fd94d13ca9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3a5813241b7b49ec8da1669262e9c741": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_72634b701a04429fb259ce1558a4c0fa",
       "IPY_MODEL_7d86bd4d43ce443890664c362d8bdca9"
      ],
      "layout": "IPY_MODEL_a8d69da9f6f642cfae387e081bb613b9"
     }
    },
    "72634b701a04429fb259ce1558a4c0fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac4d484b82c94f0f9f4065b4215f0c50",
      "max": 718,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_46a3e0b1aa044aefa1b5892ce22c7b59",
      "value": 718
     }
    },
    "7d86bd4d43ce443890664c362d8bdca9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_738d2085b8354ed08e8c679a52d81ad4",
      "placeholder": "​",
      "style": "IPY_MODEL_0656da141d3a44a69ea2320f4e05ea81",
      "value": " 718/718 [00:27&lt;00:00, 26.15ba/s]"
     }
    },
    "a8d69da9f6f642cfae387e081bb613b9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac4d484b82c94f0f9f4065b4215f0c50": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46a3e0b1aa044aefa1b5892ce22c7b59": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "738d2085b8354ed08e8c679a52d81ad4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0656da141d3a44a69ea2320f4e05ea81": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cdrc1103/MasterThesis/blob/master/Experiments/MultiClass/BERT_TPU.ipynb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZfYS_c4AvIL"
   },
   "source": [
    "### Setup Notebook"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4kryQhZfMxu2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1622646086501,
     "user_tz": -120,
     "elapsed": 53690,
     "user": {
      "displayName": "Cedric Issel",
      "photoUrl": "",
      "userId": "07537599327357681724"
     }
    },
    "outputId": "e7540157-2602-4028-de37-0aa01b71f54d"
   },
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
    "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=TPU_WORKER)\n",
    "tf.config.experimental_connect_to_cluster(resolver)\n",
    "# This is the TPU initialization code that has to be at the beginning.\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
    "strategy = tf.distribute.TPUStrategy(resolver)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TPU system grpc://10.107.111.42:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TPU system grpc://10.107.111.42:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.107.111.42:8470\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.107.111.42:8470\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU')]\n",
      "INFO:tensorflow:Found TPU system:\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fJCzGfbwJvjM"
   },
   "source": [
    "%%capture\n",
    "%matplotlib inline\n",
    "!pip install wandb\n",
    "!pip install -qq transformers\n",
    "!pip install datasets"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bd8hN16VJ72r",
    "executionInfo": {
     "elapsed": 25872,
     "status": "ok",
     "timestamp": 1622643541659,
     "user": {
      "displayName": "Cedric Issel",
      "photoUrl": "",
      "userId": "07537599327357681724"
     },
     "user_tz": -120
    },
    "outputId": "be3eca04-3ef3-49df-afd8-23028c731a7a"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XjrnXGQYA5Mg"
   },
   "source": [
    "## Data & Parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KSUYkbL8G0Vh",
    "executionInfo": {
     "elapsed": 5161,
     "status": "ok",
     "timestamp": 1622643546817,
     "user": {
      "displayName": "Cedric Issel",
      "photoUrl": "",
      "userId": "07537599327357681724"
     },
     "user_tz": -120
    },
    "outputId": "f75eb3c1-4542-426e-d61f-6520d4beacaa"
   },
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "RUN_ID = \"1.11_BERT768RES\"\n",
    "BASE_DIR = Path(f\"gdrive/MyDrive/Colab Notebooks/Thesis\")\n",
    "RUN_DIR = BASE_DIR / \"MultiClass/Runs\"\n",
    "\n",
    "# Load parameters\n",
    "class Parameter():\n",
    "  def __init__(self):\n",
    "    self.__dict__ = {\n",
    "      \"project_name\": \"thesis_multi-class\",\n",
    "      \"train_dataset\": \"train_RES.csv\",\n",
    "      \"test_dataset\": \"test_RES.csv\",\n",
    "      \"embedding_dataset\": \"bert-base-uncased\",\n",
    "      \"max_token_length\": 30, # number of words/subwords, an instance is truncated to\n",
    "      \"max_tokens\": 30000, # vocabulary size\n",
    "      \"embedding_dim\": 768, # dimension of the pre-trained embeddings\n",
    "      \"batch_size\": 32,\n",
    "      \"learning_rate\": 3e-5,\n",
    "      \"epochs\": 3,\n",
    "      \"seed\": 1, # random seed for reproducability\n",
    "      \"logging\": False, # whether to log to the wandb database (True) or to disk (False)\n",
    "      \"n_classes\": 17, # how many unique labels there are in the data set\n",
    "      \"in_feature\": \"abstract\", # feature used for training\n",
    "      \"out_feature\": \"label\", # feature to predict\n",
    "      \"sample_weights\": False, # whether weights for each training instance should be calculated depending on the label frequency\n",
    "      \"output_size\": 768, # output size of the language processing layer, i.e. the CNN, GRU etc. layer\n",
    "      \"dropout_rate\": 0.1, # for regularization\n",
    "    }\n",
    "\n",
    "# Save to disk          \n",
    "PARAMS = Parameter()\n",
    "with open(RUN_DIR / f\"{RUN_ID}.json\", \"w\") as f:\n",
    "  json.dump(PARAMS.__dict__, f)\n",
    "\n",
    "# Read data sets\n",
    "train_df = pd.read_csv(BASE_DIR / PARAMS.train_dataset, index_col=0)\n",
    "train_df = train_df.sample(frac=1, random_state=PARAMS.seed)\n",
    "test_df = pd.read_csv(BASE_DIR / PARAMS.test_dataset, index_col=0)\n",
    "test_df = test_df.sample(frac=1, random_state=PARAMS.seed)\n",
    "\n",
    "# Print stats\n",
    "print(f\"Train data set:{len(train_df)} instances\")\n",
    "print(f\"Test data set:{len(test_df)} instances\")"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Train data set:91849 instances\n",
      "Test data set:22948 instances\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fxkr8VbgTtl4"
   },
   "source": [
    "## Configure logging"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "id": "R-5Yz7jHTo3W",
    "executionInfo": {
     "elapsed": 25668,
     "status": "ok",
     "timestamp": 1622643572480,
     "user": {
      "displayName": "Cedric Issel",
      "photoUrl": "",
      "userId": "07537599327357681724"
     },
     "user_tz": -120
    },
    "outputId": "745a7916-085a-4387-8075-4ea13e253d4e"
   },
   "source": [
    "# Logging\n",
    "import wandb\n",
    "\n",
    "# log to wandb\n",
    "if PARAMS.logging:\n",
    "    !wandb login\n",
    "    run = wandb.init(project=PARAMS.project_name)\n",
    "    run.name = RUN_ID\n",
    "    log_dir = Path(wandb.run.dir)\n",
    "    wandb.config.update(PARAMS.__dict__)\n",
    "# log to disk\n",
    "else:\n",
    "    log_dir = RUN_DIR"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Paste an API key from your profile and hit enter: \n",
      "Aborted!\n",
      "Error in atexit._run_exitfuncs:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/logging/__init__.py\", line 2035, in shutdown\n",
      "    h.acquire()\n",
      "  File \"/usr/lib/python3.7/logging/__init__.py\", line 838, in acquire\n",
      "    def acquire(self):\n",
      "KeyboardInterrupt\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.31<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">dandy-lion-37</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/cdrc1103/thesis_multi-class\" target=\"_blank\">https://wandb.ai/cdrc1103/thesis_multi-class</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/cdrc1103/thesis_multi-class/runs/jsd8ma93\" target=\"_blank\">https://wandb.ai/cdrc1103/thesis_multi-class/runs/jsd8ma93</a><br/>\n",
       "                Run data is saved locally in <code>/content/wandb/run-20210602_141929-jsd8ma93</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     }
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oilWdVtbYiDd"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118,
     "referenced_widgets": [
      "db5eb39114ed491a96153a078f3ce85a",
      "6c1d41aabda24e88985ca802700cb54c",
      "5b4e4549b5c64d9088152c2ae75b5c45",
      "92bbb8bb084848acb8dc97d869644f17",
      "21268d1d8dce4e1b9c558afe247d98e4",
      "01ac43b610864af5ad6c7f4323ad649d",
      "50cd93245a284ab9b3c5cf69e4cc2e21",
      "c852a054befd4069b74de1fd94d13ca9",
      "3a5813241b7b49ec8da1669262e9c741",
      "72634b701a04429fb259ce1558a4c0fa",
      "7d86bd4d43ce443890664c362d8bdca9",
      "a8d69da9f6f642cfae387e081bb613b9",
      "ac4d484b82c94f0f9f4065b4215f0c50",
      "46a3e0b1aa044aefa1b5892ce22c7b59",
      "738d2085b8354ed08e8c679a52d81ad4",
      "0656da141d3a44a69ea2320f4e05ea81"
     ]
    },
    "id": "yAy8wMPlKO9-",
    "executionInfo": {
     "elapsed": 70363,
     "status": "ok",
     "timestamp": 1622645713483,
     "user": {
      "displayName": "Cedric Issel",
      "photoUrl": "",
      "userId": "07537599327357681724"
     },
     "user_tz": -120
    },
    "outputId": "5d3f2ddc-fdb9-4f75-ae94-03248e49f0ca"
   },
   "source": [
    "\"\"\" Dependencies \"\"\"\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense, Bidirectional, GRU, Embedding\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from transformers import TFBertModel, BertTokenizerFast, BertConfig\n",
    "from datasets import Dataset\n",
    "\n",
    "\"\"\" Apply weights to samples \"\"\"\n",
    "if PARAMS.sample_weights:\n",
    "  # Determine class weights to reduce class imbalance\n",
    "  class_weight = {}\n",
    "  total_instances = len(train_df)\n",
    "  class_freqs = train_df[PARAMS.out_feature].value_counts()\n",
    "  for class_id, freq in zip(class_freqs.index, class_freqs):\n",
    "      class_weight[class_id] = total_instances / (freq * PARAMS.n_classes)\n",
    "  sample_weight = np.zeros(len(train_df))\n",
    "  for i, class_id in enumerate(train_df[PARAMS.out_feature]):\n",
    "      sample_weight[i] = class_weight[class_id]\n",
    "\n",
    "\"\"\" Configure tokenizer \"\"\"\n",
    "config = BertConfig.from_pretrained(PARAMS.embedding_dataset)\n",
    "config.num_labels=PARAMS.n_classes\n",
    "tokenizer = BertTokenizerFast.from_pretrained(PARAMS.embedding_dataset, config=config)\n",
    "\n",
    "\"\"\" Create TF datasets \"\"\"\n",
    "# Aggregate features\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "test_ds = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Tokenize\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[PARAMS.in_feature], truncation=True, padding=True, max_length=PARAMS.max_token_length)\n",
    "train_ds = train_ds.map(tokenize, batched=True, batch_size=PARAMS.batch_size)\n",
    "test_ds = test_ds.map(tokenize, batched=True, batch_size=PARAMS.batch_size)\n",
    "\n",
    "# Transform to tensorflow data set \n",
    "train_ds.set_format(type='tensorflow', columns=['attention_mask','input_ids', 'label'])\n",
    "train_features = {x: train_ds[x].to_tensor(default_value=0) for x in ['input_ids', 'attention_mask']}\n",
    "train_ds = (train_features, to_categorical(train_ds[PARAMS.out_feature], num_classes=PARAMS.n_classes))\n",
    "# Whether to add weights to data set\n",
    "if PARAMS.sample_weights:\n",
    "  train_ds = train_ds + (sample_weight,)\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(train_ds).batch(PARAMS.batch_size)\n",
    "# Transform validation data set\n",
    "test_ds.set_format(type='tensorflow', columns=['attention_mask','input_ids', 'label'])\n",
    "test_features = {x: test_ds[x].to_tensor(default_value=0) for x in ['input_ids', 'attention_mask']}\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_features, to_categorical(test_ds[PARAMS.out_feature], num_classes=PARAMS.n_classes))).batch(32)\n",
    "\n",
    "\"\"\" Define model architecture \"\"\"\n",
    "def build_model():\n",
    "  input_ids = Input(shape=PARAMS.max_token_length, name='input_ids', dtype='int32')\n",
    "  attention_mask = Input(shape=PARAMS.max_token_length, name='attention_mask', dtype='int32')\n",
    "  transformer_model = TFBertModel.from_pretrained(PARAMS.embedding_dataset, config=config)\n",
    "  embedding = transformer_model.layers[0](input_ids, attention_mask=attention_mask)[1] \n",
    "  dropout = Dropout(PARAMS.dropout_rate)(embedding)\n",
    "  output = Dense(PARAMS.n_classes, activation='softmax')(dropout)\n",
    "  return Model(inputs={\"input_ids\": input_ids, \"attention_mask\": attention_mask}, outputs=output)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db5eb39114ed491a96153a078f3ce85a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2871.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a5813241b7b49ec8da1669262e9c741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=718.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eg4kGvJ3zQJ6"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "KNncK2M-vEAo"
   },
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "\"\"\" Transfer to TPU \"\"\"\n",
    "with strategy.scope():\n",
    "  model = build_model()\n",
    "  optimizer = tf.keras.optimizers.Adam(learning_rate=PARAMS.learning_rate, epsilon=1e-08, clipnorm=1.0)\n",
    "  loss = CategoricalCrossentropy(from_logits=False)\n",
    "  metrics = [\n",
    "    Precision(name='precision'), # tp / (tp+fp)\n",
    "    CategoricalAccuracy(name='accuracy'), # (tp+tn) / (tp+fp+tn+fn)\n",
    "    Recall(name='recall') # tp / (tp + fn)\n",
    "  ]\n",
    "  model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "  # train the model\n",
    "  history = model.fit(\n",
    "    x=train_ds,\n",
    "    epochs=PARAMS.epochs,\n",
    "    verbose=1,\n",
    "    validation_data=test_ds\n",
    "    )\n",
    "  \n",
    "pd.DataFrame(history.history).to_csv(log_dir/\"history.csv\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZTQ7qAxVyzx0"
   },
   "source": [
    "from contextlib import redirect_stdout\n",
    "\n",
    "\"\"\" Generate model summary \"\"\"\n",
    "print(model.summary())\n",
    "with open(log_dir/'model_summary.txt', 'w') as file:\n",
    "    # Pass the file handle in as a lambda function to make it callable\n",
    "    model.summary(print_fn=lambda x: file.write(x + '\\n'))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPXL4D8e1Ne5"
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cyZE4sdH1LRk"
   },
   "source": [
    "# Get predictions on test dataset\n",
    "with strategy.scope():\n",
    "  predictions = model.predict(\n",
    "      x=test_ds,\n",
    "      verbose=1,\n",
    "      batch_size=PARAMS.batch_size\n",
    "  ) # Probability distribution over the labels\n",
    "np.savetxt(log_dir/\"predictions.txt\", predictions)\n",
    "\n",
    "pred_label =np.argmax(predictions, axis=1) # select the prediction with highest probability\n",
    "true_label = test_df[PARAMS.out_feature].to_numpy() # select the true label from one-hot encoding"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qI4AAR0znCyE"
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.sans-serif\": [\"Computer Modern\"]})\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report, brier_score_loss, roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "import seaborn as sns\n",
    "import math"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UHRn3ddisLFk"
   },
   "source": [
    "\"\"\" Brier score \"\"\"\n",
    "def brier(true_label, pred_label, n_classes):\n",
    "  brier_scores = {}\n",
    "  for i in range(n_classes):\n",
    "    row_id = np.where(true_label==i)[0]\n",
    "    prob = pred_label[row_id, i]\n",
    "    true = np.ones(len(prob))\n",
    "    brier_scores[i] = brier_score_loss(true, prob).round(2)\n",
    "  return brier_scores\n",
    "brier_scores = brier(true_label, predictions, PARAMS.n_classes)\n",
    "if PARAMS.logging:\n",
    "  wandb.log({\"brier\": brier_scores})\n",
    "brier_scores"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bfuq5tV9Uy26"
   },
   "source": [
    "\"\"\" Confusion matrix \"\"\"\n",
    "def plot_cm(true_label, pred_label, n_classes):\n",
    "    # compute values\n",
    "    cm = confusion_matrix(true_label, pred_label, labels=np.arange(0,n_classes))\n",
    "    # normalize values\n",
    "    sum_per_label = np.sum(cm, axis=1)\n",
    "    cm_norm = cm / sum_per_label[:, None]\n",
    "    cm_norm =np.round(cm_norm, 2)\n",
    "    # plot\n",
    "    fig = plt.figure(figsize=(15,7))\n",
    "    sns.heatmap(cm_norm, annot=True, fmt=\".2f\")\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.tight_layout()\n",
    "    plt.plot()\n",
    "    return fig\n",
    "\n",
    "fig = plot_cm(true_label, pred_label, PARAMS.n_classes)\n",
    "fig.savefig(log_dir/\"confusion.png\", dpi=150)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Mmd02J2KVAE0"
   },
   "source": [
    "\"\"\" Receiver operating characteristic \"\"\"\n",
    "def plot_roc(true_label, pred_label, n_classes):\n",
    "    fig = plt.figure(figsize=(15, 13))\n",
    "    linewidth = 2\n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    roc_auc = {}\n",
    "    cols = math.floor(math.sqrt(n_classes))\n",
    "    rows = math.ceil(n_classes / cols)\n",
    "    \n",
    "    # calculate class-wise rocs\n",
    "    for i in range(n_classes):\n",
    "        row_id = np.where(true_label==i)[0]\n",
    "        binary_truth = np.zeros(len(true_label))\n",
    "        binary_truth[row_id] = 1\n",
    "        fpr[i], tpr[i], _ = roc_curve(binary_truth, pred_label[:,i], pos_label=1)\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        plt.plot(fpr[i], tpr[i], linewidth=linewidth,\n",
    "                 label='Label: %i (area = %0.2f)' % (i, roc_auc[i]))\n",
    "        plt.plot([0, 1], [0, 1], color='black', lw=linewidth, linestyle='--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.xlim([-0.05, 1])\n",
    "        plt.ylim([0, 1.05])\n",
    "        plt.grid(True)\n",
    "        plt.legend(loc='lower right')\n",
    "        ax = plt.gca()\n",
    "        ax.set_aspect('equal')\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "roc = plot_roc(true_label, predictions, PARAMS.n_classes)\n",
    "roc.savefig(log_dir/\"roc.png\", dpi=150)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "I5broUMl-YXn"
   },
   "source": [
    "def plot_prec(true_label, pred_label, n_classes):\n",
    "  precision = dict()\n",
    "  recall = dict()\n",
    "  average_precision = dict()\n",
    "  fig = plt.figure(figsize=(15, 13))\n",
    "  linewidth = 2\n",
    "  cols = math.floor(math.sqrt(n_classes))\n",
    "  rows = math.ceil(n_classes / cols)\n",
    "\n",
    "  for i in range(n_classes):\n",
    "      row_id = np.where(true_label==i)[0]\n",
    "      binary_truth = np.zeros(len(true_label))\n",
    "      binary_truth[row_id] = 1\n",
    "      precision[i], recall[i], _ = precision_recall_curve(binary_truth, pred_label[:,i])\n",
    "      average_precision[i] = average_precision_score(binary_truth, pred_label[:,i])\n",
    "\n",
    "      plt.subplot(rows, cols, i+1)\n",
    "      plt.plot(recall[i], precision[i], lw=linewidth, label=\"Label: %i (area = %0.2f)\" %(i, average_precision[i]))\n",
    "      plt.legend(loc='lower right')\n",
    "      plt.xlim([0.0, 1.0])\n",
    "      plt.ylim([0.0, 1.05])\n",
    "      plt.xlabel('Recall')\n",
    "      plt.ylabel('Precision')\n",
    "      f_scores = np.linspace(0.2, 0.8, num=4)\n",
    "      lines = []\n",
    "      labels = []\n",
    "      for f_score in f_scores:\n",
    "          x = np.linspace(0.01, 1)\n",
    "          y = f_score * x / (2 * x - f_score)\n",
    "          l, = plt.plot(x[y >= 0], y[y >= 0], color='gray', alpha=0.4)\n",
    "          plt.annotate('f1={0:0.1f}'.format(f_score), xy=(0.8, y[45] + 0.02), alpha=0.4)\n",
    "      ax = plt.gca()\n",
    "      ax.set_aspect('equal')\n",
    "  plt.tight_layout()\n",
    "\n",
    "  return fig\n",
    "\n",
    "prec = plot_prec(true_label, predictions, PARAMS.n_classes)\n",
    "prec.savefig(log_dir/\"prec.png\", dpi=150)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "s_0QGspPbcju"
   },
   "source": [
    "\"\"\" Classification report \"\"\"\n",
    "def create_report(true_label, pred_label, n_classes):\n",
    "  cls_names =[str(cls) for cls in np.arange(0, n_classes)]\n",
    "  cls_report = classification_report(true_label, pred_label, target_names=cls_names, output_dict=True)\n",
    "  return pd.DataFrame(cls_report).round(2).transpose()\n",
    "\n",
    "cls_report = create_report(true_label, pred_label, PARAMS.n_classes)\n",
    "cls_report.to_csv(log_dir/\"cls_report.csv\")\n",
    "if PARAMS.logging:\n",
    "  wandb.log({\"f1-score\": cls_report[\"f1-score\"].to_dict()})\n",
    "cls_report"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xv4N-nFgb0OT"
   },
   "source": [
    "## Save loggings"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jCtST7oUWcdx"
   },
   "source": [
    "\"\"\" Submit results \"\"\"\n",
    "if PARAMS.logging:\n",
    "    run.join()\n",
    "    run.finish()"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Experiment 1: Single class classification based on abstract texts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                     path  abstract  \\\nAP1605A  E:\\MLData\\thesis\\Datasets\\LexisNexis\\AP1605A.xml     False   \nAP1665A  E:\\MLData\\thesis\\Datasets\\LexisNexis\\AP1665A.xml      True   \nAP1682A  E:\\MLData\\thesis\\Datasets\\LexisNexis\\AP1682A.xml      True   \nAP1904A  E:\\MLData\\thesis\\Datasets\\LexisNexis\\AP1904A.xml      True   \nAP1937A  E:\\MLData\\thesis\\Datasets\\LexisNexis\\AP1937A.xml      True   \n\n         description  claims  label        level1labels  \nAP1605A        False   False      0                 NaN  \nAP1665A        False   False      1           Skin care  \nAP1682A        False   False      1  Active ingredients  \nAP1904A        False   False      1           Hair care  \nAP1937A        False   False      1           Packaging  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>abstract</th>\n      <th>description</th>\n      <th>claims</th>\n      <th>label</th>\n      <th>level1labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>AP1605A</th>\n      <td>E:\\MLData\\thesis\\Datasets\\LexisNexis\\AP1605A.xml</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>AP1665A</th>\n      <td>E:\\MLData\\thesis\\Datasets\\LexisNexis\\AP1665A.xml</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1</td>\n      <td>Skin care</td>\n    </tr>\n    <tr>\n      <th>AP1682A</th>\n      <td>E:\\MLData\\thesis\\Datasets\\LexisNexis\\AP1682A.xml</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1</td>\n      <td>Active ingredients</td>\n    </tr>\n    <tr>\n      <th>AP1904A</th>\n      <td>E:\\MLData\\thesis\\Datasets\\LexisNexis\\AP1904A.xml</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1</td>\n      <td>Hair care</td>\n    </tr>\n    <tr>\n      <th>AP1937A</th>\n      <td>E:\\MLData\\thesis\\Datasets\\LexisNexis\\AP1937A.xml</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1</td>\n      <td>Packaging</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "labels = pd.read_csv(\"level1_labels.csv\", index_col=0)\n",
    "features = pd.read_csv(\"../../Utilities/feature_stats.csv\", index_col=0)\n",
    "feature_stats = pd.concat([features, labels], axis=1)\n",
    "feature_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 220709\n",
      "Active ingredients              57205\n",
      "Skin care                       30095\n",
      "Packaging                       25063\n",
      "Health care                     21890\n",
      "Hair care                       21171\n",
      "Cleansing                       10824\n",
      "Sun                              8092\n",
      "Perfume                          5989\n",
      "Deo                              4243\n",
      "Non woven                        3185\n",
      "Devices                          1899\n",
      "Lip care                         1861\n",
      "Decorative cosmetic              1828\n",
      "Manufacturing technology         1737\n",
      "Shaving                           919\n",
      "Sustainability                    477\n",
      "Personalization                    86\n",
      "Artificial Intelligence (AI)        5\n",
      "no follow up                        3\n",
      "IP7 Beiersdorf                      2\n",
      "Name: level1labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "feature_stats = feature_stats[feature_stats[\"level1labels\"].notna()] # drop unlabeled patents\n",
    "feature_stats = feature_stats[feature_stats[\"abstract\"] == 1] # drop patents that don't contain an abstract\n",
    "print(f\"Number of examples: {labels.size}\")\n",
    "print(feature_stats[\"level1labels\"].value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "Skin care                   30095\nPackaging                   25063\nHealth care                 21890\nHair care                   21171\nCleansing                   10824\nSun                          8092\nPerfume                      5989\nDeo                          4243\nNon woven                    3185\nDevices                      1899\nLip care                     1861\nDecorative cosmetic          1828\nManufacturing technology     1737\nShaving                       919\nSustainability                477\nPersonalization                86\nName: level1labels, dtype: int64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a set of classes that are excluded (AI has not enough instances, the others make no sense for classification here)\n",
    "exclude_list = [\"Artificial Intelligence (AI)\", \"no follow up\", \"IP7 Beiersdorf\", \"Active ingredients\"]\n",
    "mask = feature_stats['level1labels'].isin(exclude_list)\n",
    "feature_stats =feature_stats[~mask]\n",
    "feature_stats[\"level1labels\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# create dataset\n",
    "\n",
    "# parse xml files to get features\n",
    "from PipelineBricks.parse_feature import process_files\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    feature_list = ['abstract']\n",
    "    dataset = process_files(feature_stats, feature_list)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             abstract                label\n",
      "MY168204A         NaN            Skin care\n",
      "TW200936176A      NaN  Decorative cosmetic\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"dataset2.csv\", index_col=0)\n",
    "# Add labels to dataset\n",
    "dataset[\"label\"] = feature_stats[\"level1labels\"]\n",
    "# Check if there are empty cells in abstract colmn (abstract tag exists in document but no content)\n",
    "print(dataset[dataset[\"abstract\"].isna() == True])\n",
    "# drop nan rows once again\n",
    "dataset = dataset[dataset[\"abstract\"].notna()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                         abstract  label\nAP1665A         Disclosed is an oral dosage form comprising (i...     13\nAP1904A         Light-converting material comprises a europium...      4\nAP1937A         A flexible container (1) for holding a liquid ...      9\nAP2015008920A0  The invention relates to transdermal therapeut...      5\nAP2016009265A0  An antimicrobial composition is disclosed that...      0\n...                                                           ...    ...\nYU75202A        Slabo otiruća, stabilna antiperspirant i/ili d...      8\nYU82803A        Dvofazni, sa kuglicom za nanošenje antiperspir...      9\nYU86802A        Emulzije sa malo vode su opisane koje su koris...     10\nYU86902A        This invention relates to an anhydrous cosmeti...      2\nYU96702A        This invention comprises: (1) a wet grinding m...      2\n\n[139357 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>abstract</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>AP1665A</th>\n      <td>Disclosed is an oral dosage form comprising (i...</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>AP1904A</th>\n      <td>Light-converting material comprises a europium...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>AP1937A</th>\n      <td>A flexible container (1) for holding a liquid ...</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>AP2015008920A0</th>\n      <td>The invention relates to transdermal therapeut...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>AP2016009265A0</th>\n      <td>An antimicrobial composition is disclosed that...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>YU75202A</th>\n      <td>Slabo otiruća, stabilna antiperspirant i/ili d...</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>YU82803A</th>\n      <td>Dvofazni, sa kuglicom za nanošenje antiperspir...</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>YU86802A</th>\n      <td>Emulzije sa malo vode su opisane koje su koris...</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>YU86902A</th>\n      <td>This invention relates to an anhydrous cosmeti...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>YU96702A</th>\n      <td>This invention comprises: (1) a wet grinding m...</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>139357 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert labels to categorical and create integer codes\n",
    "dataset[\"label\"] = pd.Categorical(dataset[\"label\"])\n",
    "dataset[\"label\"] = dataset[\"label\"].cat.codes\n",
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 6538/139357 [00:40<13:41, 161.66it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-7-e643ff1fcf51>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mindex\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mabstract\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"abstract\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mdetect\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mabstract\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'en'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m         \u001B[0mdataset\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"abstract\"\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\langdetect\\detector_factory.py\u001B[0m in \u001B[0;36mdetect\u001B[1;34m(text)\u001B[0m\n\u001B[0;32m    128\u001B[0m     \u001B[0mdetector\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_factory\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcreate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    129\u001B[0m     \u001B[0mdetector\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 130\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mdetector\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdetect\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    131\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    132\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\langdetect\\detector.py\u001B[0m in \u001B[0;36mdetect\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    134\u001B[0m         \u001B[0mwhich\u001B[0m \u001B[0mhas\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mhighest\u001B[0m \u001B[0mprobability\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    135\u001B[0m         '''\n\u001B[1;32m--> 136\u001B[1;33m         \u001B[0mprobabilities\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_probabilities\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    137\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mprobabilities\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    138\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mprobabilities\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlang\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\langdetect\\detector.py\u001B[0m in \u001B[0;36mget_probabilities\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    141\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget_probabilities\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    142\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlangprob\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 143\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_detect_block\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    144\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sort_probability\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlangprob\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    145\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\langdetect\\detector.py\u001B[0m in \u001B[0;36m_detect_block\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    146\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_detect_block\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    147\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcleaning_text\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 148\u001B[1;33m         \u001B[0mngrams\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_extract_ngrams\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    149\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mngrams\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    150\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0mLangDetectException\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mErrorCode\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mCantDetectError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'No features in text.'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\langdetect\\detector.py\u001B[0m in \u001B[0;36m_extract_ngrams\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    196\u001B[0m                 \u001B[0mw\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mngram\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgrams\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m-\u001B[0m\u001B[0mn\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    197\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mw\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mw\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[1;34m' '\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mw\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mword_lang_prob_map\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 198\u001B[1;33m                     \u001B[0mresult\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mw\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    199\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    200\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from langdetect import detect\n",
    "from tqdm import tqdm\n",
    "# some texts still seem to be not english\n",
    "# use language detection to filter them\n",
    "\n",
    "for index, abstract in zip(dataset.index, tqdm(dataset[\"abstract\"])):\n",
    "    if not detect(abstract) == 'en':\n",
    "        dataset.loc[index, \"abstract\"] = None\n",
    "\n",
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
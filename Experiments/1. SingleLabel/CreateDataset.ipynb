{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Experiment 1: Single label classification based on patent abstract"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load and inspect data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                     path  abstract  \\\nAP1605A  E:\\MLData\\thesis\\Datasets\\LexisNexis\\AP1605A.xml     False   \nAP1665A  E:\\MLData\\thesis\\Datasets\\LexisNexis\\AP1665A.xml      True   \nAP1682A  E:\\MLData\\thesis\\Datasets\\LexisNexis\\AP1682A.xml      True   \nAP1904A  E:\\MLData\\thesis\\Datasets\\LexisNexis\\AP1904A.xml      True   \nAP1937A  E:\\MLData\\thesis\\Datasets\\LexisNexis\\AP1937A.xml      True   \n\n         description  claims  label        level1labels  \nAP1605A        False   False      0                 NaN  \nAP1665A        False   False      1           Skin care  \nAP1682A        False   False      1  Active ingredients  \nAP1904A        False   False      1           Hair care  \nAP1937A        False   False      1           Packaging  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>abstract</th>\n      <th>description</th>\n      <th>claims</th>\n      <th>label</th>\n      <th>level1labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>AP1605A</th>\n      <td>E:\\MLData\\thesis\\Datasets\\LexisNexis\\AP1605A.xml</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>AP1665A</th>\n      <td>E:\\MLData\\thesis\\Datasets\\LexisNexis\\AP1665A.xml</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1</td>\n      <td>Skin care</td>\n    </tr>\n    <tr>\n      <th>AP1682A</th>\n      <td>E:\\MLData\\thesis\\Datasets\\LexisNexis\\AP1682A.xml</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1</td>\n      <td>Active ingredients</td>\n    </tr>\n    <tr>\n      <th>AP1904A</th>\n      <td>E:\\MLData\\thesis\\Datasets\\LexisNexis\\AP1904A.xml</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1</td>\n      <td>Hair care</td>\n    </tr>\n    <tr>\n      <th>AP1937A</th>\n      <td>E:\\MLData\\thesis\\Datasets\\LexisNexis\\AP1937A.xml</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1</td>\n      <td>Packaging</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "labels = pd.read_csv(\"level1_labels.csv\", index_col=0)\n",
    "features = pd.read_csv(\"feature_stats.csv\", index_col=0)\n",
    "feature_stats = pd.concat([features, labels], axis=1)\n",
    "feature_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 220709\n",
      "Active ingredients              57205\n",
      "Skin care                       30095\n",
      "Packaging                       25063\n",
      "Health care                     21890\n",
      "Hair care                       21171\n",
      "Cleansing                       10824\n",
      "Sun                              8092\n",
      "Perfume                          5989\n",
      "Deo                              4243\n",
      "Non woven                        3185\n",
      "Devices                          1899\n",
      "Lip care                         1861\n",
      "Decorative cosmetic              1828\n",
      "Manufacturing technology         1737\n",
      "Shaving                           919\n",
      "Sustainability                    477\n",
      "Personalization                    86\n",
      "Artificial Intelligence (AI)        5\n",
      "no follow up                        3\n",
      "IP7 Beiersdorf                      2\n",
      "Name: level1labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "feature_stats = feature_stats[feature_stats[\"level1labels\"].notna()] # drop unlabeled patents\n",
    "feature_stats = feature_stats[feature_stats[\"abstract\"] == 1] # drop patents that don't contain an abstract\n",
    "print(f\"Number of examples: {labels.size}\")\n",
    "print(feature_stats[\"level1labels\"].value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It can be seen that some labels are not relevant for the classification and that there is a huge\n",
    "class imbalance (57205 : 5). First, the irrelevant classes are dropped as well as the AI class because it\n",
    "appears only five times. Then, we test a weighting mechanism that gives less frequent classes a higher weight\n",
    "and more frequent classes a lower weight"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skin care                   30095\n",
      "Packaging                   25063\n",
      "Health care                 21890\n",
      "Hair care                   21171\n",
      "Cleansing                   10824\n",
      "Sun                          8092\n",
      "Perfume                      5989\n",
      "Deo                          4243\n",
      "Non woven                    3185\n",
      "Devices                      1899\n",
      "Lip care                     1861\n",
      "Decorative cosmetic          1828\n",
      "Manufacturing technology     1737\n",
      "Shaving                       919\n",
      "Sustainability                477\n",
      "Personalization                86\n",
      "Name: level1labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# define a set of classes that are excluded\n",
    "# (AI has not enough instances, the others make no sense for classification here)\n",
    "exclude_list = [\"Artificial Intelligence (AI)\", \"no follow up\", \"IP7 Beiersdorf\", \"Active ingredients\"]\n",
    "mask = feature_stats['level1labels'].isin(exclude_list)\n",
    "feature_stats =feature_stats[~mask]\n",
    "value_counts = feature_stats[\"level1labels\"].value_counts()\n",
    "print(value_counts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "{'Skin care': 2.3153181591626515,\n 'Packaging': 2.780173961616726,\n 'Health care': 3.1831658291457288,\n 'Hair care': 3.29127107836191,\n 'Cleansing': 6.4375,\n 'Sun': 8.610912011863569,\n 'Perfume': 11.63458006344966,\n 'Deo': 16.42222484091445,\n 'Non woven': 21.87739403453689,\n 'Devices': 36.69273301737756,\n 'Lip care': 37.44196668457818,\n 'Decorative cosmetic': 38.117888402625816,\n 'Manufacturing technology': 40.11485319516408,\n 'Shaving': 75.82100108813928,\n 'Sustainability': 146.07861635220127,\n 'Personalization': 810.2267441860465}"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate weights\n",
    "class_weights = {}\n",
    "total_instances = len(feature_stats)\n",
    "for class_id, freq in zip(feature_stats[\"level1labels\"].value_counts().index, feature_stats[\"level1labels\"].value_counts()):\n",
    "    class_weights[class_id] = (1 / freq)*(total_instances)/2.0\n",
    "class_weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Parse Patent Files\n",
    "Parse patent files for their abstract if they're labeled with one of the remaining classes."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 139359/139359 [13:22<00:00, 173.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# parse xml files to get features\n",
    "from PipelineBricks.parse_feature import process_files\n",
    "dataset = pd.DataFrame\n",
    "if __name__ == \"__main__\":\n",
    "    feature_list = ['abstract']\n",
    "    dataset = process_files(feature_stats, feature_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It can happen that abstract tags in the cml file of the patent exist but the text value is an empty\n",
    "string. We need to filter these instances."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [abstract, label_encoded, label]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Add labels to dataset\n",
    "dataset[\"label\"] = feature_stats[\"level1labels\"]\n",
    "# Check if there are empty cells in abstract column (abstract tag exists in document but no content)\n",
    "print(dataset[dataset[\"abstract\"].isna() == True])\n",
    "# drop nan rows once again\n",
    "dataset = dataset[dataset[\"abstract\"].notna()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Cleansing',\n",
      " 1: 'Decorative cosmetic',\n",
      " 2: 'Deo',\n",
      " 3: 'Devices',\n",
      " 4: 'Hair care',\n",
      " 5: 'Health care',\n",
      " 6: 'Lip care',\n",
      " 7: 'Manufacturing technology',\n",
      " 8: 'Non woven',\n",
      " 9: 'Packaging',\n",
      " 10: 'Perfume',\n",
      " 11: 'Personalization',\n",
      " 12: 'Shaving',\n",
      " 13: 'Skin care',\n",
      " 14: 'Sun',\n",
      " 15: 'Sustainability'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "# convert labels to categorical and create integer codes\n",
    "dataset[\"label\"] = pd.Categorical(dataset[\"label\"])\n",
    "dataset[\"label_encoded\"] = dataset[\"label\"].cat.codes\n",
    "# Assigned categories\n",
    "pprint(dict(enumerate(dataset[\"label\"].cat.categories)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"dataset.csv\", index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Correct the class imbalance\n",
    "Approach 1: Over-sampling (create duplicates) of less frequent classes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instances in train set: \n",
      "13    22570\n",
      "9     18797\n",
      "5     16417\n",
      "4     15878\n",
      "0      8118\n",
      "14     6069\n",
      "10     4492\n",
      "2      3182\n",
      "8      2389\n",
      "3      1424\n",
      "6      1396\n",
      "1      1370\n",
      "7      1303\n",
      "12      689\n",
      "15      358\n",
      "11       65\n",
      "Name: label_encoded, dtype: int64\n",
      "instances in test set: \n",
      "13    7524\n",
      "9     6266\n",
      "5     5473\n",
      "4     5293\n",
      "0     2706\n",
      "14    2023\n",
      "10    1497\n",
      "2     1061\n",
      "8      796\n",
      "3      475\n",
      "6      465\n",
      "1      457\n",
      "7      434\n",
      "12     230\n",
      "15     119\n",
      "11      21\n",
      "Name: label_encoded, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# split into train and test part first to avoid that the test set has duplicates of\n",
    "# of data in train set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(dataset[[\"abstract\", \"label_encoded\"]], test_size=0.25,\n",
    "                               random_state=1, stratify=dataset[\"label_encoded\"])\n",
    "\n",
    "print(f'instances in train set: \\n{train[\"label_encoded\"].value_counts()}')\n",
    "print(f'instances in test set: \\n{test[\"label_encoded\"].value_counts()}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We only care about the train dataset for the resampling."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12    1880\n",
      "15     923\n",
      "11     165\n",
      "Name: label_encoded, dtype: int64\n",
      "13    3854\n",
      "9     3076\n",
      "4     2685\n",
      "5     2662\n",
      "Name: label_encoded, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "oversampling_ids = [11, 15, 12]\n",
    "sampling_factor = 4\n",
    "\n",
    "# oversampling\n",
    "min_classes = train[train[\"label_encoded\"].isin(oversampling_ids)]\n",
    "oversampled = min_classes.sample(n=len(min_classes)*sampling_factor, replace=True, random_state=1)\n",
    "print(oversampled[\"label_encoded\"].value_counts())\n",
    "\n",
    "# # undersampling\n",
    "# maj_classes = train[train[\"label_encoded\"].isin(undersampling_ids)]\n",
    "# undersampled = maj_classes.sample(n=math.ceil(len(maj_classes)/sampling_factor), replace=True, random_state=1)\n",
    "# print(undersampled[\"label_encoded\"].value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# concatenate dataframes\n",
    "train = pd.concat([train, oversampled], axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Export"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "train.to_csv(\"train.csv\")\n",
    "test.to_csv(\"test.csv\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pathlib\n",
    "from Utilities.directories import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define directories to load raw data from and to save serialized data to\n",
    "root_dir = pathlib.Path(data + \"/example_extrect_ma\")\n",
    "save_dir = pathlib.Path(data + \"/example_extract-tfecord\")\n",
    "dataset = tf.data.Dataset.list_files(str(root_dir/'*'), seed=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bytes_list {\n",
      "  value: \"some string\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(_bytes_feature(b'some string'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def serialize_example(feature0, feature1):\n",
    "    \"\"\"\n",
    "    Creates a tf.train.Example message ready to be written to a file.\n",
    "    \"\"\"\n",
    "    # Create a dictionary mapping the feature name to the tf.train.Example-compatible\n",
    "    # data type.\n",
    "\n",
    "    feature = {\n",
    "        \"feature0\": _bytes_feature(feature0),\n",
    "        \"feature1\": _int64_feature(feature1)\n",
    "    }\n",
    "\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "b'\\n)\\n\\x14\\n\\x08feature0\\x12\\x08\\n\\x06\\n\\x04test\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x0f'"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the serialization\n",
    "\n",
    "serialized_example = serialize_example(feature0=b'test', feature1=15)\n",
    "serialized_example"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'E:\\\\MLData\\\\thesis\\\\Datasets\\\\1.Abstract-SingleClass\\\\train-1-122203.tfrec']\n",
      "int64_list {\n",
      "  value: 3\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert back\n",
    "\n",
    "import tensorflow as tf\n",
    "from Utilities.directories import lexis_abstract\n",
    "import pathlib\n",
    "\n",
    "features = {\n",
    "    'abstract': tf.io.FixedLenFeature([], tf.string),\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64)\n",
    "}\n",
    "train_files = tf.data.Dataset.list_files(str(lexis_abstract) + \"\\*train*.tfrec\")\n",
    "print(list(train_files.as_numpy_iterator()))\n",
    "test_file = str(pathlib.Path.joinpath(lexis_abstract, \"validate-1-15276.tfrec\"))\n",
    "dataset = tf.data.TFRecordDataset(filenames=[test_file], compression_type=\"ZLIB\")\n",
    "raw_example = next(iter(dataset))\n",
    "parsed = tf.train.Example.FromString(raw_example.numpy())\n",
    "print(parsed.features.feature['label'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from to_tfrecord import TFRecordsConverter\n",
    "from Utilities.directories import data\n",
    "\n",
    "# Convert to tfRecord\n",
    "if __name__ == '__main__':\n",
    "    output_dir = pathlib.Path.joinpath(data, \"1.Abstract-SingleClass\")\n",
    "    converter = TFRecordsConverter(feature_stats, output_dir, 0.1, 0.1)\n",
    "    converter.convert()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load Huggingface transformer\n",
    "from transformers import BertConfig, BertTokenizerFast\n",
    "\n",
    "# Then what you need from tensorflow.keras\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from Utilities.directories import lexis_abstract\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_files = tf.data.Dataset.list_files(file_pattern=str(lexis_abstract) + \"\\*train*.tfrec\")\n",
    "test_files = tf.data.Dataset.list_files(file_pattern=str(lexis_abstract) + \"\\*test*.tfrec\")\n",
    "validation_files = tf.data.Dataset.list_files(file_pattern=str(lexis_abstract) + \"\\*validate*.tfrec\")\n",
    "\n",
    "features = {\n",
    "    'abstract': tf.io.FixedLenFeature([], tf.string),\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64)\n",
    "}\n",
    "\n",
    "test_dataset = tf.data.TFRecordDataset(filenames=test_files, compression_type=\"ZLIB\")\n",
    "\n",
    "\n",
    "def _parse_function(example_proto, features):\n",
    "    return tf.io.parse_single_example(example_proto, features)\n",
    "\n",
    "def select_data_from_record(record):\n",
    "    x = record['abstract']\n",
    "    y = record['label']\n",
    "    return (x, y)\n",
    "\n",
    "parsed_dataset = test_dataset.map(lambda record: _parse_function(record, features))\n",
    "parsed_dataset = parsed_dataset.map(select_data_from_record)\n",
    "\n",
    "for p in parsed_dataset:\n",
    "    print(p)\n",
    "    break\n",
    "\n",
    "\n",
    "# https://colab.research.google.com/drive/1yWaLpCWImXZE2fPV0ZYDdWWI8f52__9A#scrollTo=BmMlC1i0COBW\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}